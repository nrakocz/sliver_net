{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T21:40:17.240788Z",
     "start_time": "2020-02-28T21:40:17.237525Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"  # GPU ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T21:40:17.487541Z",
     "start_time": "2020-02-28T21:40:17.244393Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T21:40:20.882113Z",
     "start_time": "2020-02-28T21:40:17.489867Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_databunch import *\n",
    "from exp.fastai_imports import  *\n",
    "from exp.amish_sites import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T21:40:20.936875Z",
     "start_time": "2020-02-28T21:40:20.885148Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import torch\n",
    "from exp.nb_databunch import *\n",
    "from exp.fastai_imports import  *\n",
    "from exp.amish_sites import *\n",
    "\n",
    "class AmishDataset(Dataset):\n",
    "\n",
    "    def __init__(self, items, df, pathologies,csv_file=None, transform=None,index_col='CASE_ID',data_type=None,cov=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            items (list): list of all imgs\n",
    "            pathology (string): desired pathology\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        if(df is not None):\n",
    "            self.df = df\n",
    "        else:\n",
    "            try:\n",
    "                self.df = pd.read_csv(csv_file,index_col=index_col)\n",
    "            except:\n",
    "                print('Warning no data-frame was provided!')\n",
    "                self.df=None\n",
    "                \n",
    "        self.items = items\n",
    "        self.pathologies = pathologies\n",
    "        self.transform = transform\n",
    "        self.index_col = index_col\n",
    "        self.pred_i = 0\n",
    "        self.data_type=data_type\n",
    "        self.cov = cov\n",
    "    \n",
    "    def filter_by_func(self,func):\n",
    "        self.items = [f for f in self.items if(func(f))]\n",
    "        return self\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = self.items[idx]\n",
    "        \n",
    "        # 3 steps: 1. read image, 2. copy 3x, 3. convert to pillow image\n",
    "        image = io.imread(img_name)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        pheno = getMlutiLabel(img_name,self.pathologies,self.df,self.data_type)\n",
    "        if(self.pathologies!='eye'): pheno = pheno.astype(np.float32)\n",
    "        if(isinstance(pheno,pd.Series)): pheno = pheno.values\n",
    " \n",
    " \n",
    "        # return sample\n",
    "        return image, pheno\n",
    "    \n",
    "    def show_preds(self,preds=None,n=9,pred_i=None,label_preds=None):\n",
    "        r,c = int(np.ceil(np.sqrt(n))),int(np.round(np.sqrt(n)))\n",
    "        fig,axes = plt.subplots(r,c,figsize=(4*c,4*r))\n",
    "        \n",
    "        i_start = self.pred_i if pred_i is None else pred_i\n",
    "        self.pred_i = i_start + n\n",
    "        \n",
    "        for i,ax in enumerate(axes.ravel()):\n",
    "            img_t = self[i+i_start][0]\n",
    "            img_true = self[i+i_start][1]\n",
    "            img_p = [f'{p:.3f}' for p in preds[i+i_start]] if label_preds is None else label_preds[i+i_start] \n",
    "            \n",
    "            ax.imshow(img_t.data.numpy()[0],cmap='gray')\n",
    "            ax.set_title(f'{i+i_start}: {img_true} / {img_p}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T21:40:21.184325Z",
     "start_time": "2020-02-28T21:40:20.938801Z"
    }
   },
   "outputs": [],
   "source": [
    "!python notebook2script.py AmishDataLoaders.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T21:40:21.251802Z",
     "start_time": "2020-02-28T21:40:21.186779Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t']\n",
    "\n",
    "for s in [1,2,3,4,5,7,9]:\n",
    "    \n",
    "    a = list(range(97))\n",
    "    n=len(a)\n",
    "\n",
    "\n",
    "    print(s)\n",
    "    m = n//2\n",
    "    \n",
    "\n",
    "    n2=n\n",
    "    a=a[m-n2//2:m+1+n2//2]\n",
    "    print(a)\n",
    "    print()\n",
    "\n",
    "\n",
    "    m=len(a)//2\n",
    "    print(a[m])\n",
    "    \n",
    "    b=a[m::s]\n",
    "    c = a[:m+1][::-1][::s][::-1][:-1]\n",
    "\n",
    "    n3 = np.ceil((n2//2+1)/s)\n",
    "    n4 = 2*n3-1\n",
    "    print(c+b, len(c+b),n4)\n",
    "    print(b)\n",
    "    print(c)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T21:40:21.290383Z",
     "start_time": "2020-02-28T21:40:21.253602Z"
    }
   },
   "outputs": [],
   "source": [
    "b = []\n",
    "n=0\n",
    "for i in range(4):\n",
    "    a = []\n",
    "    for j in range(3):\n",
    "        n+=1\n",
    "        a.append(n)\n",
    "    b.append(a)\n",
    "\n",
    "c = np.array(b+[[]])[:-1]\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T21:40:21.327137Z",
     "start_time": "2020-02-28T21:40:21.293293Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def permuteList(l,seed=42):\n",
    "    np.random.seed(seed)\n",
    "    n = len(l)\n",
    "    \n",
    "    l_arr = np.array(l+[[]])[:-1]\n",
    "    perm = np.random.permutation(n)\n",
    "    np.random.seed()\n",
    "\n",
    "    return list(l_arr[perm])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T22:40:00.393524Z",
     "start_time": "2020-02-28T22:40:00.311971Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from itertools import groupby \n",
    "from multiprocessing import Process\n",
    "import multiprocessing\n",
    "import torchvision.transforms.functional as TF\n",
    "import PIL\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "class AmishVolumeDataset(AmishDataset):\n",
    "    \"\"\"pass in a list of volume ids\"\"\"\n",
    "    def __init__(self, items, df, pathologies, csv_file=None, do_transform=True,unif_transform=True,index_col='CASE_ID',n_workers=1,\n",
    "                resize=None,\n",
    "                rcrop_size=None,\n",
    "                rotation=None,\n",
    "                hflip=None,\n",
    "                contrast=False,\n",
    "                n_slices=None,\n",
    "                tiled=False,\n",
    "                classification=False,\n",
    "                mode='train',\n",
    "                data_type = None,\n",
    "                cov = None,\n",
    "                slice_dsamp=1,\n",
    "                group_func = lambda f: f.name.split('_')[:4],\n",
    "                sort_key=None\n",
    "                 \n",
    "                ):\n",
    "        \n",
    "        super().__init__(items, df, pathologies,csv_file, transform,index_col)\n",
    "        self.items.sort(key=sort_key)\n",
    "        self.img_items = self.items\n",
    "        self.items = [list(i) for j, i in groupby(self.items,group_func)]\n",
    "        self.n_workers = n_workers\n",
    "        self.resize = resize\n",
    "        self.rcrop_size = rcrop_size\n",
    "        self.rotation = rotation\n",
    "        self.hflip = hflip\n",
    "        self.contrast = contrast\n",
    "        self.unif_transform = unif_transform\n",
    "        self.n_slices = n_slices\n",
    "        self.tiled = tiled\n",
    "        self.do_transform = do_transform\n",
    "        self.classification = classification\n",
    "        self.mode = mode\n",
    "        self.csv_file=csv_file\n",
    "        self.data_type = data_type\n",
    "        self.cov = cov\n",
    "        self.slice_dsamp = slice_dsamp\n",
    "        \n",
    "        if(mode=='train'):\n",
    "            self.tfms = compose( [transforms.RandomCrop(self.rcrop_size),\n",
    "                                 transforms.RandomRotation(self.rotation),\n",
    "                                 transforms.RandomHorizontalFlip()]\n",
    "                              )\n",
    "        \n",
    "        \n",
    "    \n",
    "    def get_rand_params(self,image):\n",
    "        \n",
    "        if(self.rcrop_size is not None):\n",
    "            self.crop_params = transforms.RandomCrop.get_params(transforms.Resize(size=self.resize)(image), output_size=self.rcrop_size)\n",
    "        if(self.rotation is not None):\n",
    "            self.rand_angle = transforms.RandomRotation.get_params(self.rotation)\n",
    "        if(self.hflip is not None):\n",
    "            self.rand_flip = random.random() > 0.5\n",
    "    \n",
    "    def _transform(self,slices):\n",
    "        # Resize\n",
    "        if(self.resize is not None):\n",
    "            slices = [transforms.Resize(size=self.resize)(image) for image in slices]\n",
    "            \n",
    "        #contrast\n",
    "        if(self.contrast):\n",
    "            slices = [pil_contrast_strech()(image) for image in slices]\n",
    "        \n",
    "        if(self.mode=='train'):\n",
    "            if self.do_transform:    \n",
    "                if self.unif_transform: # different randomized trnasformation for each slice\n",
    "                    self.get_rand_params(slices[0])\n",
    "                    slices = [self.u_transform(image) for image in slices]\n",
    "                else:  # different randomized trnasformation for each slice\n",
    "                    slices = [self.tfms(image) for image in slices]\n",
    "                \n",
    "        return [TF.to_tensor(image) for image in slices]\n",
    "        \n",
    "        \n",
    "    def u_transform(self, image):\n",
    "        \n",
    "        #crop\n",
    "        if(self.rcrop_size is not None):\n",
    "            image = TF.crop(image,*self.crop_params)\n",
    "        \n",
    "            \n",
    "        #rotate\n",
    "        if(self.rotation is not None):           \n",
    "            image = TF.rotate(image, self.rand_angle)\n",
    "\n",
    "        #flip\n",
    "        if(self.hflip is not None):\n",
    "            if(self.rand_flip):\n",
    "                image = TF.hflip(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        v = self.get_img(idx)\n",
    "        pheno = self.get_pheno(idx)\n",
    "        return v,pheno\n",
    "        \n",
    "    def get_img(self,idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # get idx\n",
    "        vol_list = self.items[idx]\n",
    "        vol_list.sort(key=lambda f: int(f.stem.split('_')[-1]))\n",
    "        img_name = vol_list[0]\n",
    "        \n",
    "        # grab desired slices\n",
    "        if(self.n_slices is not None):\n",
    "            m = len(vol_list)//2\n",
    "            vol_list = vol_list[m-self.n_slices//2:m+1+self.n_slices//2]\n",
    "            \n",
    "        if(self.slice_dsamp>1): #down sample resolution\n",
    "            n_slice = len(vol_list)\n",
    "            m = n_slice//2\n",
    "            \n",
    "            upper= vol_list[m::self.slice_dsamp]\n",
    "            lower= vol_list[-m::-self.slice_dsamp][::-1][:-1]\n",
    "            vol_list = lower + upper\n",
    "              \n",
    "        #open imgages\n",
    "        slices = [PIL.Image.open(i) for i in vol_list]\n",
    "        \n",
    "        # transfrom (resize, crop, rotate  ,contrast, etc.)\n",
    "        slices = self._transform(slices)\n",
    "            \n",
    "        # reshape\n",
    "        if(self.tiled):\n",
    "            v = torch.cat(slices,dim=1) \n",
    "            v = torch.stack([v,v,v]).squeeze()\n",
    "        else:\n",
    "            v = torch.stack(slices).squeeze()      \n",
    "        \n",
    "            \n",
    "        # add covariants\n",
    "        if(self.cov is not None):\n",
    "            v_cov = getMlutiLabel(img_name,self.cov,self.df,self.data_type)\n",
    "            v = (v,v_cov.astype(np.float32).values)\n",
    "        \n",
    "        return v\n",
    "\n",
    "    def get_pheno(self,idx):\n",
    "        \n",
    "        vol_list = self.items[idx]\n",
    "        vol_list.sort(key=lambda f: int(f.stem.split('_')[-1]))\n",
    "        img_name = vol_list[0]\n",
    "        \n",
    "        # grab target\n",
    "        pheno = getMlutiLabel(img_name,self.pathologies,self.df,self.data_type)\n",
    "        if(self.pathologies=='eye'):\n",
    "            pheno = np.array([0,1],dtype=np.float32) if(pheno=='OD') else np.array([1,0],dtype=np.float32)\n",
    "        else:\n",
    "            pheno = pheno.astype(np.float32)\n",
    "            if(isinstance(pheno,pd.Series)): pheno = pheno.values\n",
    "            elif(self.classification): pheno = np.array([0,1],dtype=np.float32) if(pheno) else np.array([1,0],dtype=np.float32)\n",
    "\n",
    "        return pheno\n",
    "    \n",
    "    def filter_by_func(self,func):\n",
    "        self.items = [vl for vl in self.items if(func(vl[0]))]\n",
    "        return self\n",
    "    \n",
    "    @staticmethod\n",
    "    def flatten(l):\n",
    "        return [item for sublist in l for item in sublist]\n",
    "\n",
    "    def split_dataset(self,shuffle_dataset=False, pct=0.2,random_seed=None):\n",
    "        dataset_size = len(self.items)\n",
    "        indices = list(range(dataset_size))\n",
    "        split = int(np.floor(pct * dataset_size))\n",
    "        if shuffle_dataset :\n",
    "            np.random.seed(random_seed)\n",
    "            np.random.shuffle(indices)\n",
    "        train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "        train_items = self.flatten(np.array(self.items)[train_indices])\n",
    "        val_items = self.flatten(np.array(self.items)[val_indices])\n",
    "\n",
    "\n",
    "        ds_tr = AmishVolumeDataset(train_items, \n",
    "                                    df=self.df, \n",
    "                                    pathologies=self.pathologies,\n",
    "                                    csv_file=self.csv_file, \n",
    "                                    do_transform=self.do_transform,\n",
    "                                    unif_transform=self.unif_transform,\n",
    "                                    index_col=self.index_col,\n",
    "                                    n_workers=self.n_workers,\n",
    "                                    resize=self.resize,\n",
    "                                    rcrop_size=self.rcrop_size,\n",
    "                                    rotation=self.rotation,\n",
    "                                    hflip=self.hflip,\n",
    "                                    contrast=self.contrast,\n",
    "                                    n_slices=self.n_slices,\n",
    "                                    tiled=self.tiled,\n",
    "                                    classification=self.classification,\n",
    "                                    mode='train',\n",
    "                                    data_type=self.data_type,\n",
    "                                    cov = self.cov,\n",
    "                                    slice_dsamp = self.slice_dsamp\n",
    "                                  )\n",
    "\n",
    "        ds_tst = AmishVolumeDataset(val_items, \n",
    "                                    df=self.df, \n",
    "                                    pathologies=self.pathologies,\n",
    "                                    csv_file=self.csv_file, \n",
    "                                    do_transform=self.do_transform,\n",
    "                                    unif_transform=self.unif_transform,\n",
    "                                    index_col=self.index_col,\n",
    "                                    n_workers=self.n_workers,\n",
    "                                    resize=self.resize,\n",
    "                                    rcrop_size=self.rcrop_size,\n",
    "                                    rotation=self.rotation,\n",
    "                                    hflip=self.hflip,\n",
    "                                    contrast=self.contrast,\n",
    "                                    n_slices=self.n_slices,\n",
    "                                    tiled=self.tiled,\n",
    "                                    classification=self.classification,\n",
    "                                    mode='test',\n",
    "                                    data_type=self.data_type,\n",
    "                                    cov = self.cov,\n",
    "                                    slice_dsamp = self.slice_dsamp\n",
    "                                   )\n",
    "\n",
    "\n",
    "        return ds_tr, ds_tst\n",
    "\n",
    "\n",
    "class  pil_contrast_strech(object):\n",
    "    def __init__(self,low=2,high=98):\n",
    "        self.low,self.high = low,high\n",
    "        \n",
    "    def __call__(self,img):\n",
    "        # Contrast stretching\n",
    "        img=np.array(img)\n",
    "        plow, phigh = np.percentile(img, (self.low, self.high))\n",
    "        return PIL.Image.fromarray(exposure.rescale_intensity(img, in_range=(plow, phigh)))\n",
    "    \n",
    "    def eye2array(pheno):\n",
    "        np.array([0,1],dtype=np.float32) if(pheno=='OD') else np.array([1,0],dtype=np.float32) if(pheno=='OS') else np.array([-1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T22:44:35.059711Z",
     "start_time": "2020-02-28T22:44:34.812065Z"
    }
   },
   "outputs": [],
   "source": [
    "!python notebook2script.py AmishDataLoaders.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T03:11:33.301597Z",
     "start_time": "2019-09-25T03:11:33.263541Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def split_dataset(dataset, batch_size=64, \n",
    "                  num_workers=4, shuffle_dataset=False, pct=0.2,random_seed=None):\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor(pct * dataset_size))\n",
    "    if shuffle_dataset :\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "    train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "    # Creating PT data samplers and loaders:\n",
    "    train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = torch.utils.data.sampler.SubsetRandomSampler(val_indices)\n",
    "    \n",
    "    \n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                               sampler=train_sampler)\n",
    "    validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                    sampler=valid_sampler)\n",
    "    \n",
    "    return train_loader, validation_loader\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T22:40:09.949582Z",
     "start_time": "2020-02-28T22:40:09.705946Z"
    }
   },
   "outputs": [],
   "source": [
    "!python notebook2script.py AmishDataLoaders.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-27T02:56:49.122058Z",
     "start_time": "2019-09-27T02:56:49.087957Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "cat_cols?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T03:11:40.152656Z",
     "start_time": "2019-09-25T03:11:39.204183Z"
    }
   },
   "outputs": [],
   "source": [
    "amish_csv = 'AMISH_SO_QC.csv'\n",
    "amish_df = pd.read_csv(amish_csv,index_col='CASE_ID')\n",
    "data_path =  Path('./miami_imgs_e2e_par_full/Cube/')\n",
    "\n",
    "amish_df = validateNumerical(amish_df)\n",
    "amish_df = binarizeDataFrame(amish_df,cat_cols)\n",
    "files_list= get_files(data_path,extensions='.tiff',recurse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T16:42:09.182223Z",
     "start_time": "2019-09-25T16:42:09.149532Z"
    }
   },
   "outputs": [],
   "source": [
    "pathologies = [\"SO_SRTSRHRM\", \"SO_INTRA_RCS\",\n",
    "           \"SO_OUTER_RT\", \"SO_SR_DRUSEN\", \"SO_HRF_IRHRFOND\", \"SO_HRF_HRFOD\",\n",
    "           \"SO_PED_DPED\", \"SO_PED_HPED\",'CO_RPE_A3MM','CO_RPE_A5MM','CO_RPE_V3MM','CO_RPE_V5MM']\n",
    "\n",
    "#pathologies = ['CO_RPE_A3MM','CO_RPE_A5MM','CO_RPE_V3MM','CO_RPE_V5MM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T16:42:10.454284Z",
     "start_time": "2019-09-25T16:42:10.421742Z"
    }
   },
   "outputs": [],
   "source": [
    "isInAmishDf = partial(isInDf,df=amish_df)\n",
    "areValidpathologiesLabels = partial(areValidLabels,pathologies=pathologies,df=amish_df)\n",
    "isValidLabelPathology =  partial(isValidLabel,pathology=pathologies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T23:53:13.719000Z",
     "start_time": "2019-09-11T23:53:13.627862Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pathologies = ['SO_SRTSRHRM','SO_SRTSRHRM','SO_INTRA_RCS']\n",
    "\n",
    "ds = (AmishDataset(files_list,df=amish_df,pathologies=pathologies)\n",
    "    .filter_by_func(lambda f: 'Line' in f.name)\n",
    "    .filter_by_func(lambda f: 'Unknown' not in f.name)\n",
    "    .filter_by_func(isInAmishDf)\n",
    "    .filter_by_func(areValidpathologiesLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T23:53:14.906393Z",
     "start_time": "2019-09-11T23:53:14.709308Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T16:42:13.646888Z",
     "start_time": "2019-09-25T16:42:13.149694Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "ds = AmishVolumeDataset(files_list,df=amish_df,pathologies=pathologies,n_workers=-1,\n",
    "                        resize=(256,256),\n",
    "                        rcrop_size=(224,224),\n",
    "                        rotation=(-10,10),\n",
    "                        do_transform=True,\n",
    "                        unif_transform=False,\n",
    "                        contrast=True,\n",
    "                        hflip=True,\n",
    "                        n_slices=7,\n",
    "                        tiled=True,\n",
    "                        mode='train'\n",
    "                       )\n",
    "\n",
    "ds = (ds.filter_by_func(isInAmishDf)\n",
    "        .filter_by_func(lambda f: 'Unknown' not in f.name)\n",
    "        .filter_by_func(lambda f: 'ERROR' not in f.name)\n",
    "        .filter_by_func(areValidpathologiesLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T16:42:20.218884Z",
     "start_time": "2019-09-25T16:42:19.920402Z"
    }
   },
   "outputs": [],
   "source": [
    "tr,tst = ds.split_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T16:42:21.161291Z",
     "start_time": "2019-09-25T16:42:21.127320Z"
    }
   },
   "outputs": [],
   "source": [
    "len(tr),len(tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T16:45:22.654468Z",
     "start_time": "2019-09-25T16:44:59.077540Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check for NaN\n",
    "\n",
    "for i in range(len(tr)):\n",
    "    V,p = tr[i]\n",
    "    if(np.isnan(p).sum()):\n",
    "        print(i)\n",
    "        print(p)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T16:46:11.806870Z",
     "start_time": "2019-09-25T16:46:11.771578Z"
    }
   },
   "outputs": [],
   "source": [
    "print(V.shape)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T03:18:47.793436Z",
     "start_time": "2019-09-25T03:18:47.380963Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fix,ax = plt.subplots(figsize=(5,20))\n",
    "ax.imshow(V.data.numpy()[0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T21:01:43.544484Z",
     "start_time": "2019-09-20T21:01:43.136468Z"
    }
   },
   "outputs": [],
   "source": [
    "V,p = tst[0]\n",
    "print(V.shape)\n",
    "p\n",
    "fix,ax = plt.subplots(figsize=(5,20))\n",
    "ax.imshow(V.data.numpy()[0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T21:01:45.591399Z",
     "start_time": "2019-09-20T21:01:45.558149Z"
    }
   },
   "outputs": [],
   "source": [
    "dl = DataLoader(ds,batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T21:01:54.793170Z",
     "start_time": "2019-09-20T21:01:47.821288Z"
    }
   },
   "outputs": [],
   "source": [
    "# %debug\n",
    "x,y = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T20:58:38.244343Z",
     "start_time": "2019-09-20T20:58:38.207549Z"
    }
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T17:02:32.952101Z",
     "start_time": "2019-09-17T17:02:32.911203Z"
    }
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T04:39:53.958543Z",
     "start_time": "2019-09-13T04:39:53.908228Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %debug\n",
    "transforms.ToPILImage()(V[40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# MISC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T20:16:57.419748Z",
     "start_time": "2019-09-20T20:16:56.991918Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trtmp = []\n",
    "for i in tr:\n",
    "    trtmp.append(getPatID(i)[0])\n",
    "    \n",
    "trtmp= list(set(trtmp))\n",
    "\n",
    "\n",
    "tstmp = []\n",
    "\n",
    "for i in tst:\n",
    "    tstmp.append(getPatID(i)[0])\n",
    "    \n",
    "tstmp= list(set(tstmp))\n",
    "\n",
    "[i for i in trtmp if i in tstmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T20:39:33.394978Z",
     "start_time": "2019-09-11T20:39:33.360621Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filter_funcs = [isInAmishDf,lambda f: 'Line' in f.name]\n",
    "\n",
    "filter_funcs = [partial(filter_list,func=func) for func in filter_funcs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T20:51:41.315765Z",
     "start_time": "2019-09-11T20:51:41.181029Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "compose(filter_funcs)(files_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
