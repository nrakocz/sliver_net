
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: dev_nb/predict_vol_amish.ipynb

from exp.nb_databunch import *
from exp.fastai_imports import *
from exp.nb_AmishDataLoaders import *
from exp.amish_sites import *
from exp.resultsNplots import *
from exp.nb_spatiailMaxPooling import SpatialMaxPooling
from exp.resnet3d import resnet18 as resnet18_3d

from datetime import datetime
import seaborn as sns



def isPosLabel(fname,pathology,df=None):
    case_id,eye = getPatID(fname)

    #default df
    df = amish_df if df is None else df

    #get label:
    label = df.loc[case_id,f'{pathology}_{eye}']

    if(label):return True
    return False


# pathologies = ["SO_SRTSRHRM", "SO_INTRA_RCS",
#              "SO_OUTER_RT", "SO_SR_DRUSEN", "SO_HRF_IRHRFOND", "SO_HRF_HRFOD",
#              "SO_PED_DPED", "SO_PED_HPED"]

# pathologies='SO_PED_DPED' #'eye' # 'SO_PED_DPED'

# binary_p = ["SO_SRTSRHRM", "SO_INTRA_RCS",
#               "SO_SR_DRUSEN", "SO_HRF_IRHRFOND", "SO_HRF_HRFOD",
#              "SO_PED_DPED",]
#=============================================
# combine binary with continuous biomarkers
#=============================================
binary_p = ["SO_SR_DRUSEN", "SO_HRF_IRHRFOND", "SO_HRF_HRFOD",
           'CO_RPE_V3MM_L0.03',
            'CO_Drusen_Core',
            'IRP_RP'] #'CO_RPE_V3MM_YN'

reg_p = ['CO_RPE_A3MM',
        'CO_RPE_A5MM',
        'CO_RPE_V3MM',
        'CO_RPE_V5MM',
        'CO_GA_A5MM']

pathologies = binary_p #binary_p + reg_p
#==============================================

# pathologies='Gender'#,'Gender'
covariants =  None #['Gender','Age']


class BCE_MSE_Loss(torch.nn.Module):
    def __init__(self,n_bin,n_reg=None, size_average=None, reduce=None, reduction='mean',alpha=0.5):
        super(BCE_MSE_Loss, self).__init__()
        self.size_average = size_average
        self.reduce = reduce
        self.reduction=reduction
        self.n_bin = n_bin
        self.n_reg = n_reg
        self.alpha = alpha

    def forward(self, input, target):
        bce_component = F.binary_cross_entropy_with_logits(input[:, 0:self.n_bin], target[:, 0:self.n_bin], reduction=self.reduction)
        mse_component = F.mse_loss(input[:, self.n_bin:], target[:, self.n_bin:], reduction=self.reduction)

        return self.alpha*bce_component + (1-self.alpha)*mse_component


class NonAdaptiveConcatPool2d(nn.Module):
    "Layer that concats `AdaptiveAvgPool2d` and `AdaptiveMaxPool2d`."
    def __init__(self, kernel_size):
        super(NonAdaptiveConcatPool2d,self).__init__()
        self.kernel_size = kernel_size
        self.ap = nn.AvgPool2d(kernel_size)
        self.mp = nn.MaxPool2d(kernel_size)

    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)


class covModel(torch.nn.Module):
    def __init__(self, model,input_size,pretrain_path=None,n_out=1,ncov=0):
        super(covModel, self).__init__()
        if(pretrain_path is not None):model.load_state_dict(torch.load(pretrain_path)['model'])
        model = nn.Sequential(*list(model.children())[:-2])
        self.model = nn.Sequential(model,NonAdaptiveConcatPool2d(8))
        self.cov_model = FeatureCNN(input_size,ncov=ncov,n_out=n_out)

    def forward(self,x,cov=None):
        x = self.model(x)
        return self.cov_model(x.squeeze(dim=-1),cov)

class FeatureCNN(torch.nn.Module):
    def __init__(self,input_size,n_out=1, input_channels=1024,ncov=0,kernel_size=3):
        super(FeatureCNN, self).__init__()
        self.ncov = ncov
        self.conv1 = torch.nn.Conv1d(input_channels, 16, kernel_size=kernel_size, stride=1, padding=0)
        # output size: N-(kernel_size-1)
        self._conv2_filters = 32
        self.conv2 = torch.nn.Conv1d(16, self._conv2_filters, kernel_size=kernel_size, stride=1, padding=0)
        # output size: N-2(kernel_size-1)
        self.pool = torch.nn.MaxPool1d(kernel_size=4, stride=4, padding=0)
        # output size: (N-2(kernel_size-1))//pool_stride
        self._output_size = (input_size-2*(kernel_size-1))//4
        self.fc1 = torch.nn.Linear(self._conv2_filters * self._output_size+ncov, 24)
        self.fc2 = torch.nn.Linear(24, n_out)
    def forward(self,x,cov=None):
        x = self.conv1(x)
        x = F.relu(x)
        x = self.conv2(x)
        x = F.relu(x)
        x = self.pool(x)

        x = x.view(-1, self._conv2_filters * self._output_size)
        if(self.ncov): x=torch.cat((x,cov),dim=1)
        x = self.fc1(x)
        x = F.relu(x)
        x = self.fc2(x)
        return x

import torchvision.models as tmodels
# from OCT_app.octpred.models.resnet3d import resnet18 as resnet18_3d

def getArch(model_name,data,loss_func,path,model_dir,ds_params,
                MODEL_PATH = '/opt/data/workingdir/nrakocz/oct/models/kermany/resnet18/models/best.pth',
                multi_gpu=False,
                ncov=0
):
    """
    '3D_CNN',
    'SLIVER-NET',
    'Tile-Resnet',
    'Tile-Resnet-Scratch',
    'SLIVER-scratch',
    'ImageNet-SLIVER'
    """
    sliver_models = ['SLIVER-NET','ImageNet-SLIVER','SLIVER-scratch']
    learn_params = {'loss_func':loss_func, 'path':path, 'model_dir':model_dir}

    n_slices = ds_params['n_slices']
    slice_res = ds_params['slice_dsamp']

    n_tmp = np.ceil((n_slices//2+1)/slice_res)
    number_of_slices_tot = int(2*n_tmp-1)
    #==============================================
    if(model_name in sliver_models):

        if(model_name=='SLIVER-NET'):
            model = tmodels.resnet18(num_classes=4)
            model = covModel(model,number_of_slices_tot,n_out=data.c,pretrain_path=MODEL_PATH,ncov=ncov)

        #------------------------------------------

        elif(model_name=='ImageNet-SLIVER'):
            model = tmodels.resnet18(pretrained=True)
            model = covModel(model,number_of_slices_tot,n_out=data.c)

        #-------------------------------------------

        elif(model_name=='SLIVER-scratch'):
            model = tmodels.resnet18(num_classes=4)
            model = covModel(model,number_of_slices_tot,n_out=data.c,pretrain_path=None)

        #-------------------------------------------
        if(multi_gpu): model = torch.nn.DataParallel(model)

        learn = Learner(data=data,
            model = model,
            **learn_params)

        if('scratch' not in model_name):
            if(multi_gpu):
                learn.split(lambda m: (m.module.model,m.module.cov_model))
            else:
                learn.split(lambda m: (m.model,m.cov_model))

            learn.freeze()


    #==============================================

    elif(model_name=='Tile-Resnet'):
        model = tmodels.resnet18(num_classes=4)
        model.load_state_dict(torch.load(MODEL_PATH)['model'])

        learn = cnn_learner(data=data,
            base_arch=lambda _:model,
            pretrained=True,
            **learn_params)
        if(multi_gpu):
            learn.model = torch.nn.DataParallel(learn.model)


    #-------------------------------------------

    elif(model_name=='Tile-Resnet-Scratch'):
        model = tmodels.resnet18

        learn = cnn_learner(data=data,
                    base_arch=model,
                    pretrained=False,
                    **learn_params)

        if(multi_gpu): learn.model = torch.nn.DataParallel(learn.model)


    #-------------------------------------------
    elif(model_name=='3D_CNN'):
        model = resnet18_3d(num_classes=data.c)
        learn = Learner(data = data,
                        model=model,
                        **learn_params)

        if(multi_gpu): learn.model = torch.nn.DataParallel(learn.model)

    #-------------------------------------------

    else:
        raise ValueError('Invalid architecture')

    return learn

def getNparams(learn):
    model_parameters = filter(lambda p: p.requires_grad, learn.model.parameters())
    n_params = sum([np.prod(p.size()) for p in model_parameters])
    return n_params


def scores2medians(scores):
    return np.median(np.array(scores),axis=0)

def scores2means(scores):
    return np.mean(np.array(scores),axis=0)


def CI_str(score,lower,upper):
    return f'{score:.2f}[{lower:.2f},{upper:.2f}]'

def MedianCI(model_name,res_dicts,pathologies,verbose=False,bl_roc=None,bl_pr=None,median=True):

    sum_stat_func = scores2medians if(median) else scores2means
    bootstrap_rocs = []
    bootstrap_prs = []
    rocs = []
    prs = []

    for res_dict,p in zip(res_dicts,pathologies):
        roc_ci,pr_ci,fpr,tpr,precision, recall,rocs_us,prs_us = res_dict[model_name]

        bootstrap_rocs.append(rocs_us)
        bootstrap_prs.append(prs_us)
        rocs.append(roc_ci[0])
        prs.append(pr_ci[0])

    roc_med = sum_stat_func(rocs)
    pr_med = sum_stat_func(prs)

    bootstrap_roc_med = sum_stat_func(bootstrap_rocs)
    bootstrap_pr_med = sum_stat_func(bootstrap_prs)

    bootstrap_roc_med_sorted = np.sort(bootstrap_roc_med)
    bootstrap_pr_med_sorted = np.sort(bootstrap_pr_med)

    n_iter = len(bootstrap_roc_med)
    med_roc_ci = (roc_med,bootstrap_roc_med_sorted[int(0.025*n_iter)],bootstrap_roc_med_sorted[int(0.975*n_iter)])
    med_pr_ci = (pr_med,bootstrap_pr_med_sorted[int(0.025*n_iter)],bootstrap_pr_med_sorted[int(0.975*n_iter)])

    roc_p_val = f'{scores_pval(bl_roc,bootstrap_roc_med):.2f}' if bl_roc is not None else 'Baseline'
    pr_p_val = f'{scores_pval(bl_pr,bootstrap_pr_med):.2f}' if bl_pr is not None else 'Baseline'

    if(verbose):
        model_name = str(model_name)
        print(f'{model_name:<20s}\t{CI_str(*med_roc_ci)}\t{CI_str(*med_pr_ci)}\t{roc_p_val}\t{pr_p_val}')

    return med_roc_ci, med_pr_ci, bootstrap_roc_med, bootstrap_pr_med,rocs,prs


def scores_pval(bl_score,score):
    score_diff = np.array(bl_score) - np.array(score)
    score_pval = max((score_diff > 0).sum(),1)/len(score_diff)
    return score_pval